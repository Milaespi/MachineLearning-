# üé¨ GUION PARA VIDEO EXPLICATIVO - APLICACI√ìN DE MACHINE LEARNING

## üìã ESTRUCTURA DEL VIDEO (3 INTEGRANTES)

---

## üé• **INTRODUCCI√ìN (30 segundos)**
**Todos los integrantes juntos**

- "Hola, somos [Nombre 1], [Nombre 2] y [Nombre 3]"
- "Hoy les presentamos nuestra aplicaci√≥n web de Machine Learning que predice el abandono de clientes y realiza clustering de tarjetas de cr√©dito"
- "Utilizamos tres modelos: Regresi√≥n Log√≠stica, K-Nearest Neighbors y K-Means"

---

## üë§ **INTEGRANTE 1: REGRESI√ìN LOG√çSTICA (3-4 minutos)**

### 1. Introducci√≥n al modelo (30 seg)
- "Yo me encargu√© del modelo de **Regresi√≥n Log√≠stica**"
- "Este es un modelo supervisado de clasificaci√≥n que predice la probabilidad de que un cliente abandone el servicio"
- "Utiliza el dataset de Telco Customer Churn"

### 2. Explicaci√≥n t√©cnica breve (1 min)
- "La Regresi√≥n Log√≠stica calcula la probabilidad usando una funci√≥n sigmoide"
- "Es ideal para problemas de clasificaci√≥n binaria (Abandono: S√≠/No)"
- "Entrenamos el modelo con variables como g√©nero, servicios contratados, facturaci√≥n, etc."

### 3. Demostraci√≥n en la web (2 min)
- Abrir la aplicaci√≥n web
- Seleccionar "Regresi√≥n Log√≠stica" en el sidebar
- **Completar el formulario con datos ficticios:**
  - G√©nero: Masculino
  - Adulto Mayor: No
  - Pareja: S√≠
  - Dependientes: No
  - Tiempo: 24 meses
  - Servicios: Completar todos los campos
  - Facturaci√≥n: Cargos mensuales y totales
- Hacer clic en "Predecir"
- **Mostrar y explicar los resultados:**
  - "Como pueden ver, el modelo predice una probabilidad de abandono del X%"
  - "La clasificaci√≥n es: [S√≠/No] Abandono"
  - **Explicar la tabla de probabilidades:**
    - "Esta tabla muestra la probabilidad de abandono vs no abandono"
    - "El gr√°fico de barras visualiza estas probabilidades"
  - "El modelo tambi√©n muestra un indicador de progreso que representa la probabilidad"

### 4. Reflexi√≥n personal (30 seg)
- **Dificultades:** "Tuve que lidiar con el preprocesamiento de datos categ√≥ricos y num√©ricos"
- **Aprendizaje:** "Aprend√≠ c√≥mo funciona la funci√≥n sigmoide y c√≥mo interpretar probabilidades"
- **Mejora:** "Podr√≠amos agregar m√°s variables o usar t√©cnicas de balanceo de clases"

---

## üë§ **INTEGRANTE 2: K-NEAREST NEIGHBORS - KNN (3-4 minutos)**

### 1. Introducci√≥n al modelo (30 seg)
- "Yo trabaj√© con el modelo **K-Nearest Neighbors (KNN)**"
- "Es un algoritmo supervisado que clasifica bas√°ndose en los 'k' vecinos m√°s cercanos"
- "Tambi√©n usa el dataset de Telco Customer Churn"

### 2. Explicaci√≥n t√©cnica breve (1 min)
- "KNN busca los k clientes m√°s similares en el dataset de entrenamiento"
- "La clasificaci√≥n se basa en la mayor√≠a de los vecinos m√°s cercanos"
- "Es un algoritmo no param√©trico, no hace suposiciones sobre la distribuci√≥n de los datos"
- "Elegimos k=5 despu√©s de validar con diferentes valores"

### 3. Demostraci√≥n en la web (2 min)
- Seleccionar "K-Nearest Neighbors (KNN)" en el sidebar
- **Usar los MISMOS datos que el Integrante 1** (para comparar)
- Hacer clic en "Predecir"
- **Mostrar y explicar los resultados:**
  - "KNN clasifica este cliente como: [S√≠/No] Abandono"
  - "A diferencia de Regresi√≥n Log√≠stica, KNN no da probabilidades, solo clasificaci√≥n"
  - **Explicar la diferencia:**
    - "Regresi√≥n Log√≠stica nos da una probabilidad (ej: 65% de abandono)"
    - "KNN nos da una clasificaci√≥n directa (S√≠ o No)"
  - "Esto es √∫til cuando solo necesitamos saber si un cliente va a abandonar o no"

### 4. Reflexi√≥n personal (30 seg)
- **Dificultades:** "Tuve que normalizar los datos y encontrar el valor √≥ptimo de k"
- **Aprendizaje:** "Comprend√≠ c√≥mo funciona la distancia euclidiana y la importancia de normalizar datos"
- **Mejora:** "Podr√≠amos implementar diferentes m√©tricas de distancia o usar validaci√≥n cruzada para optimizar k"

---

## üë§ **INTEGRANTE 3: K-MEANS CLUSTERING (3-4 minutos)**

### 1. Introducci√≥n al modelo (30 seg)
- "Yo implement√© el modelo **K-Means Clustering**"
- "Es un algoritmo no supervisado que agrupa clientes en clusters seg√∫n sus caracter√≠sticas"
- "Utiliza el dataset de Credit Card para clustering"

### 2. Explicaci√≥n t√©cnica breve (1 min)
- "K-Means agrupa clientes similares en clusters"
- "No necesita etiquetas, encuentra patrones por s√≠ solo"
- "Usamos el m√©todo del codo y silhouette para encontrar el n√∫mero √≥ptimo de clusters"
- "Encontramos que 4 clusters es el n√∫mero √≥ptimo"

### 3. Demostraci√≥n en la web (2 min)
- Seleccionar "K-Means Clustering" en el sidebar
- **Completar el formulario con datos ficticios de tarjeta de cr√©dito:**
  - **Tab "Balance y Compras":**
    - Saldo: 2000
    - Compras: 1500
    - Compras √∫nicas: 800
    - Compras a plazos: 700
  - **Tab "Frecuencias":**
    - Frecuencia de compras: 0.5
    - Frecuencia √∫nica: 0.3
    - Frecuencia a plazos: 0.2
  - **Tab "Pagos y L√≠mites":**
    - Pagos m√≠nimos: 200
    - Pagos completos: 1500
    - L√≠mite de cr√©dito: 10000
    - Tiempo (meses): 12
- Hacer clic en "Predecir"
- **Mostrar y explicar los resultados:**
  - "El cliente fue asignado al Cluster [n√∫mero]"
  - **Explicar el perfil del cluster:**
    - "Este cluster representa clientes con [caracter√≠sticas]"
    - "Por ejemplo: clientes con saldo medio, compras moderadas, etc."
  - **Mostrar la tabla de caracter√≠sticas del cluster:**
    - "Esta tabla muestra el perfil promedio del cluster"
    - "Nos ayuda a entender qu√© tipo de cliente es"

### 4. Reflexi√≥n personal (30 seg)
- **Dificultades:** "Fue desafiante interpretar los clusters y crear perfiles significativos"
- **Aprendizaje:** "Aprend√≠ sobre clustering no supervisado y c√≥mo interpretar resultados sin etiquetas"
- **Mejora:** "Podr√≠amos usar t√©cnicas de reducci√≥n de dimensionalidad como PCA para visualizar mejor los clusters"

---

## ü§ù **REFLEXI√ìN FINAL - TODOS JUNTOS (2-3 minutos)**

### Dificultades encontradas (1 min)
**Integrante 1:** "El preprocesamiento de datos fue complejo, especialmente manejar valores faltantes y variables categ√≥ricas"

**Integrante 2:** "Encontrar el valor √≥ptimo de k para KNN requiri√≥ mucha experimentaci√≥n y validaci√≥n"

**Integrante 3:** "Interpretar los clusters y crear perfiles significativos fue desafiante sin etiquetas previas"

### Qu√© aprendieron (1 min)
**Integrante 1:** "Aprend√≠ sobre modelos supervisados, probabilidades y c√≥mo interpretar resultados de clasificaci√≥n"

**Integrante 2:** "Comprend√≠ algoritmos basados en instancias y la importancia de la normalizaci√≥n de datos"

**Integrante 3:** "Aprend√≠ sobre aprendizaje no supervisado y c√≥mo encontrar patrones en datos sin etiquetas"

**Todos:** "Aprendimos a integrar modelos de ML en una aplicaci√≥n web funcional usando Streamlit"

### C√≥mo podr√≠an mejorar el sistema (1 min)
- **Integrante 1:** "Agregar m√°s variables o usar t√©cnicas de balanceo de clases para mejorar la precisi√≥n"
- **Integrante 2:** "Implementar validaci√≥n cruzada para optimizar hiperpar√°metros autom√°ticamente"
- **Integrante 3:** "Usar t√©cnicas de reducci√≥n de dimensionalidad para visualizar clusters mejor"
- **Todos:** "Podr√≠amos agregar m√°s visualizaciones, implementar autenticaci√≥n de usuarios, o desplegar en la nube"

---

## üé¨ **CIERRE (30 segundos)**
**Todos juntos**

- "Gracias por ver nuestra presentaci√≥n"
- "Pueden encontrar el c√≥digo en nuestro repositorio de GitHub: [enlace]"
- "Cualquier pregunta, estamos a su disposici√≥n"

---

## üìù **NOTAS IMPORTANTES PARA LA GRABACI√ìN:**

1. **Datos ficticios consistentes:** Usar los mismos datos para Regresi√≥n Log√≠stica y KNN para poder comparar resultados

2. **Tiempo total:** Aproximadamente 12-15 minutos

3. **Transiciones:** Cada integrante debe hacer una transici√≥n suave al siguiente

4. **Pantalla compartida:** Mostrar claramente la aplicaci√≥n web y los resultados

5. **Explicar las tablas:** No solo mostrar, sino explicar qu√© significan los n√∫meros

6. **Comparar modelos:** Mencionar las diferencias entre los modelos supervisados (Regresi√≥n Log√≠stica vs KNN)

---

## üéØ **PUNTOS CLAVE A DESTACAR:**

‚úÖ **Regresi√≥n Log√≠stica:** Da probabilidades (0-100%)
‚úÖ **KNN:** Da clasificaci√≥n directa (S√≠/No)
‚úÖ **K-Means:** Agrupa clientes similares sin etiquetas previas
‚úÖ **Aplicaci√≥n funcional:** Interfaz web interactiva
‚úÖ **Modelos entrenados:** Pre-cargados y listos para usar
‚úÖ **Visualizaciones:** Gr√°ficos y tablas para interpretar resultados


